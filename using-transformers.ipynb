{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056289a8-7091-4eea-8c78-9c07c2e8878a",
   "metadata": {},
   "source": [
    "# Behind the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64dbd2c-a686-415c-89cd-bcfed76acbb3",
   "metadata": {},
   "source": [
    "We will be looking under the hood of the following classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c634cb-45ff-4212-89d8-eaa300ed039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/opt/anaconda3/envs/hf_nlp_course/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\n",
    "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af28b32-a66c-48d0-9d71-6191d857b388",
   "metadata": {},
   "source": [
    "Under the hood, the pipeline tokenizes the raw text into numeric inputs and passes them to the model. It takes the model's output of logit probabilities, and conducts post-processing to convert the output into predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d27f87d-7f4f-4c30-b7e0-d8144a52da85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\"\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde081e9-0411-4171-a01a-8469909b830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate model outputs\n",
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d4a8f-4a36-4785-aff3-7fa4fafaa5b6",
   "metadata": {},
   "source": [
    "The model consists of embeddings, layers, hidden states and a head, which can be configured for different purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5003acb2-ed27-4217-bb83-768fa749b571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "182087c3-5bc0-4f71-a09f-ec7b52234095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# generate model outputs for classification\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)\n",
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "454ff0ae-be03-4e60-9f6b-9e9ddd86dc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0195e-02, 9.5980e-01],\n",
      "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# convert outputs to probabilities\n",
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a394b2c8-2244-471e-9fe1-ad179db9e52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'NEGATIVE', 1: 'POSITIVE'}\n"
     ]
    }
   ],
   "source": [
    "# get labels from model\n",
    "print(model.config.id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf01c795-a1d7-45bd-a167-37a63ba6655f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dcbdde-cde2-4c16-a178-412aca9062df",
   "metadata": {},
   "source": [
    "Models can be created from the model configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13242a4d-6d78-4d8b-95a3-0f9c82ad01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model from model configs\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "configs = BertConfig()\n",
    "model = BertModel(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4089e99c-2492-4901-95d3-af84d0f3ef1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.32.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f0ee6b8-28f6-4c5d-9a79-8311bbbbe488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from checkpoint\n",
    "checkpoint = \"bert-base-cased\"\n",
    "model = BertModel.from_pretrained(checkpoint)\n",
    "\n",
    "# save model to disk\n",
    "model.save_pretrained(\"saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85cf2552-ab3d-49e5-b152-34cf26daf1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  8667,   106,   102],\n",
      "        [  101, 13297,   119,   102],\n",
      "        [  101,  8835,   106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hf_nlp_course/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize input and generate output\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "encoded_sequences = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04483c5d-10cb-41a2-b229-dab43829c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**encoded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0cda22-72ee-4fe6-b434-3f138461cda5",
   "metadata": {},
   "source": [
    "# Playing with tokenizer and model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "098a3651-9bc0-4f97-9f95-66a5de5e594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much! Why?\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3fa14eec-d0ab-4c10-8061-a48ab739e987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 768])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9d51f91a-7758-45f6-9fea-da2884493b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0195e-02, 9.5980e-01],\n",
       "        [9.9944e-01, 5.6230e-04]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)\n",
    "softmax(outputs.logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "148d8e93-b879-47b9-8e8b-619220766d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "66e407a0-e150-4548-8d70-4be17d13a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]\n",
    "inputs = tokenizer(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "17c385ad-0dc7-49af-a716-bc402d91ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101, 7592, 999, 102], [101, 4658, 1012, 102], [101, 3835, 999, 102]]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1fbc5ff2-db92-48ff-88f5-fef6401ee80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_tensor = torch.tensor(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "46b909da-666b-4307-aa85-affe5e324345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 7592,  999,  102],\n",
       "        [ 101, 4658, 1012,  102],\n",
       "        [ 101, 3835,  999,  102]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4723ce68-2201-4282-bee3-c806874611e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "550fc85c-d52e-4814-a160-850b5efce970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.7235,  3.9691],\n",
       "        [-4.2219,  4.5807],\n",
       "        [-4.2852,  4.6166]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d3a6b224-95f2-48fa-b80a-bb00e55f60fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 19204, 4697, 2033, 2023, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"tokenize me this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "63c96c0e-f92d-4b78-be1b-3775bb16c0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 22559, 3708, 1143, 1142, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer(\"tokenize me this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d5e8d1c0-ee9b-48db-8b00-10254aff3af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['token', '##ize', 'me', 'this', '!']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"tokenize me this!\"\n",
    "tokenized_sequence = tokenizer.tokenize(sequence)\n",
    "tokenized_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9b96ec82-8264-4235-a8cb-1e458fd953f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22559, 3708, 1143, 1142, 106]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.convert_tokens_to_ids(tokenized_sequence)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "87d1f5e7-7b86-4d87-9bfc-38fca5ac5579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9917e-01, 8.3222e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "sequence = \"How can something come from nothing?\"\n",
    "\n",
    "tokenized_sequence = tokenizer.tokenize(sequence)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokenized_sequence)\n",
    "input_ids = torch.tensor([ids])\n",
    "\n",
    "output = model(input_ids)\n",
    "print(softmax(output.logits, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ee638bc9-8bc4-45ba-b216-98e8d7387045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 3.9118, -3.1788]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a538e196-57a5-4847-b0e0-1e4ac1baf283",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2d1282c6-d9eb-4c9a-9ed8-5b4b58286f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who are you? \" \n",
      " \" i'm not a reporter. i've just come from the newspaper. \" she 'd already gotten her name and number from a friend. she wasn't going to waste the time of the person who 'd written that story. \n",
      " she didn't want to risk any more chances. the press would be after her. they 'd find out about her, and they wouldn't stop until they got to her father. her own father, who was in a coma. he 'd\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "checkpoint = \"openai-gpt\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
    "\n",
    "sequence = \"Who are you?\"\n",
    "input_ids = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=100,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eef9bb-6844-4dfa-be6b-b2923b32f3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
